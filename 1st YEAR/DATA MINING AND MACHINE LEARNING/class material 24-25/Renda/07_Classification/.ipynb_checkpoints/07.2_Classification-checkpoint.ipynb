{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [The *data leakage* pitfall](#The-Data-Leakage-pitfall-(docs))\n",
    "- [The *inconsistent preprocessing* pitfall](#The-Inconsistent-Preprocessing-pitfall-(docs))\n",
    "- [scikit-learn pipelines: Chaining estimators](#sklearn-Pipelines:-Chaining-estimators)\n",
    "    - [Building and using a pipeline](#Building-and-using-a-pipeline)\n",
    "    - [Accessing the steps of a pipeline](#Accessing-the-steps-of-a-pipeline)\n",
    "    - [Pipeline and cross-validation](#Pipeline-and-cross-validation)\n",
    "    - [Imbalanced classification and cross-validation](#Imbalanced-classification-and-cross-validation)\n",
    "- [Classifiers comparison](#Classifiers-comparison)\n",
    "    - [Wilcoxon signed-rank test](#Wilcoxon-signed-rank-test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **data mining workflow** involves several steps, including (but not limited to) feature selection, normalization, sampling, classifier training and so on.\n",
    "\n",
    "The need to combine these steps in a program paves the way to possible **methodological errors**; the most common one are **data leakage** and **inconsistent preprocessing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Data Leakage* pitfall ([docs](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage))\n",
    "\n",
    "Data leakage occurs when information that would not be available at prediction time is used when building the model. \n",
    "\n",
    "This results in overly optimistic performance estimates, for example from cross-validation, and thus poorer performance when the model is used on actually novel data, for example during production. \n",
    "\n",
    "A common cause is not keeping the test and train data subsets separate. **Test data should never be used to make choices about the model**. The general rule is to never call `fit` on the test data.\n",
    "Note that the same considerations apply for cross-validation, which can be viewed as an iteration of train-test splits.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Inconsistent Preprocessing* pitfall ([docs](https://scikit-learn.org/stable/common_pitfalls.html#inconsistent-preprocessing))\n",
    "\n",
    "Both train and test data subsets should receive the same preprocessing transformation: if data transformation operations (normalization, unsupervised dimensionality reduction, feature extraction, ...)  are used when training a model, they also must be used on subsequent datasets, whether it’s test data or data in a production system. Otherwise, the feature space will change, and the model will not be able to perform effectively. \n",
    "\n",
    "It is important that these transformations are only learnt from the training data. For example, if you have a normalization step where you divide by the average value, the average should be the average of the train subset, not the average of all the data. If the test subset is included in the average calculation, information from the test subset is influencing the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "breast = datasets.load_breast_cancer()\n",
    "X, y = breast.data, breast.target\n",
    "print(breast.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Wrong #1: data leakage </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, random_state = 42)\n",
    "y_pred = LogisticRegression().fit(X_train, y_train).predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> What's wrong here: parameters for scaling (mean and variance) are estimated on the whole dataset (that is, also on the test set)</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Wrong #2 inconsistent preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "scaler = StandardScaler()\n",
    "X_train_new = scaler.fit_transform(X_train)\n",
    "\n",
    "y_pred = LogisticRegression().fit(X_train_new, y_train).predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red>What's wrong here: the train dataset is scaled, whereas the test dataset is not, so model performance on the test dataset is worse than expected.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Right</font>\n",
    "- <font color = green> split your data into train and test **first**</font>\n",
    "- <font color = green> learn your transformation on training data and apply an *all* data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "scaler = StandardScaler()\n",
    "X_train_new = scaler.fit_transform(X_train) # fit only on training set\n",
    "X_test_new = scaler.transform(X_test) # transform also the test\n",
    "\n",
    "y_pred = LogisticRegression().fit(X_train_new, y_train).predict(X_test_new)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have illustrated data leakage and inconsistent preprocessing with a standardization transformation. \n",
    "\n",
    "This risk of methodological mistake is however relevant with almost all transformations in scikit-learn, including (but not limited to) feature selection, SimpleImputer, PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red>Feature selection: Wrong (data leakage)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_14636\\191616997.py\", line 1, in <module>\n",
      "    from sklearn.feature_selection import SelectKBest\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\__init__.py\", line 84, in <module>\n",
      "    from .base import clone\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 11, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 8, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 11, in <module>\n",
      "    from scipy.sparse import csr_matrix, issparse\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\scipy\\sparse\\__init__.py\", line 295, in <module>\n",
      "    from ._csr import *\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelectKBest\n\u001b[0;32m      2\u001b[0m X_selected \u001b[38;5;241m=\u001b[39m SelectKBest(k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(X, y)\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_selected, y, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\__init__.py:84\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     ]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\utils\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\scipy\\sparse\\__init__.py:295\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DMML\\Lib\\site-packages\\scipy\\sparse\\_csr.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _spbase, sparray\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0;32m     12\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "X_selected = SelectKBest(k = 2).fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, random_state = 42)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<font color = red>What's wrong here: la selezione delle feature viene effettuata prima della divisione tra training e test set.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Feature selection: Right </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "selector = SelectKBest(k = 2)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_selected, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "y_pred = clf.predict(X_test_selected)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Recap](https://scikit-learn.org/stable/common_pitfalls.html#how-to-avoid-data-leakage) - below are some tips on avoiding data leakage:\n",
    "\n",
    "- Always split the data into train and test subsets first, particularly before any preprocessing steps.\n",
    "\n",
    "- Never include test data when using the `fit` and `fit_transform` methods. Using all the data, e.g., `fit(X)`, can result in overly optimistic scores. Conversely, the `transform` method should be used on both train and test subsets as the same preprocessing should be applied to all the data. This can be achieved by using `fit_transform` on the train subset and `transform` on the test subset.\n",
    "\n",
    "- The **scikit-learn pipeline** is a great way to prevent data leakage as it ensures that the appropriate method is performed on the correct data subset. The pipeline is ideal for use in cross-validation and hyper-parameter tuning functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn` Pipelines: Chaining estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One or more transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator.\n",
    "\n",
    "Consider the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization** ➡️ **Feature Selection** ➡️ **Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "selector = SelectKBest(k = 2)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_selected, y_train)\n",
    "        \n",
    "X_test_selected = selector.transform(scaler.transform(X_test))\n",
    "y_pred = clf.predict(X_test_selected)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code becomes more tricky, and it is easier to make mistakes.\n",
    "\n",
    "**Pipelines can be used to chain multiple estimators into one**, and serve multiple purpose:\n",
    "- **Convenience and encapsulation**: you only have to call **fit and predict once on your data** to fit a whole sequence of estimators.\n",
    "- Joint parameter selection: you can **grid search over parameters of all estimators** in the pipeline at once.\n",
    "- Safety: pipelines help **avoid data leakage from your test data into the trained model**, by ensuring that the same samples are used to train the transformers and predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All estimators in a pipeline, except the last one, must be transformers (i.e. must have a `transform` method). The last estimator may be any type (transformer, classifier, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and using a `pipeline`\n",
    "The Pipeline is built using a list of **(key, value) pairs**, where \n",
    "- the key is a string containing the name you want to give this step \n",
    "- the value is an estimator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [('scaling', StandardScaler()),\n",
    "              ('feature-selection', SelectKBest(k = 2)), \n",
    "              ('clf', LogisticRegression())]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility function `make_pipeline` is a shorthand for constructing pipelines; it takes a variable number of estimators and returns a pipeline, filling in the names automatically:\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(), SelectKBest(k=2), LogisticRegression())\n",
    "```\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `fit` on the pipeline is the same as \n",
    "- sequentially calling `fit` on each estimator\n",
    "- `transform` the input and pass it on to the next step. \n",
    "\n",
    "Furthermore, **the pipeline has all the methods that the last estimator in the pipeline has**, i.e. if the last estimator is a classifier, the Pipeline can be used as a classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the steps of a `pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the steps of a `pipeline` in three ways:\n",
    "- throught the `steps` attribute\n",
    "- by index\n",
    "- by name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['scaling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[0].mean_, pipe[0].var_ # mean_ and var_ are used by StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline (*scaling* --> *feature-selection* --> *clf*) can be evaluated on the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(10, shuffle = True, random_state = 21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "results_fsel = cross_validate(pipe, # In previous notebook we had just a classifier here\n",
    "                         X,\n",
    "                         y,\n",
    "                         scoring = {'fscore': make_scorer(f1_score),\n",
    "                                    'accuracy': make_scorer(accuracy_score)},\n",
    "                         return_estimator = True,\n",
    "                         cv = skf,\n",
    "                         n_jobs = -1) \n",
    "results_fsel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced classification and cross-validation\n",
    "\n",
    "We know that `scikit-learn` does not natively handle methods for *imbalanced learning*, but `imblearn` does.\n",
    "\n",
    "We can use the pipelines of imblearn in exactly the same way as those of scikit-learn, so that we can correctly perform rebalancing when working in cross-validation.\n",
    "\n",
    "```python\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('sampling', SMOTE()),\n",
    "        ... ,\n",
    "        ('classification', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "results = cross_val_score(pipe, X, y, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often the case that we want to compare different classifiers, or different configurations of parameters.\n",
    "We can approach this problem using statistical analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we want to assess whether using feature-selection is beneficial or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Choose the metric to look at: f-score is an option (an averaging strategy must be adopted if we have multiple classes)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Evaluate the metric distributions fairly (same test splits)**\n",
    "- we already have results for the *features-selection* experiment\n",
    "- we use the same `skf` object for the *no-features-selection* experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('scaling', StandardScaler()), \n",
    "              ('clf', LogisticRegression())]\n",
    "pipe_noFsel = Pipeline(estimators)\n",
    "pipe_noFsel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nofsel = cross_validate(pipe_noFsel,\n",
    "                         X,\n",
    "                         y,\n",
    "                         scoring = {'fscore': make_scorer(f1_score),\n",
    "                                    'accuracy': make_scorer(accuracy_score)},\n",
    "                         return_estimator = True,\n",
    "                         cv = skf,\n",
    "                         n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fsel['test_fscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nofsel['test_fscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fsel['test_fscore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nofsel['test_fscore'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Look at the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({'fsel': results_fsel['test_fscore'],\n",
    "                        'nofsel': results_nofsel['test_fscore']})\n",
    "metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "ax = metrics.boxplot(figsize = (3, 3))\n",
    "ax.set_ylabel('f-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Apply a statistical test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical tests\n",
    "- [t-test for paired samples](https://en.wikipedia.org/wiki/Student%27s_t-test#Dependent_t-test_for_paired_samples) ([scipy ref](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html))\n",
    "- [Wilcoxon signed-rank test](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test) ([scipy ref](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html))\n",
    "    - serves the same purpose of student *t*-test for matched samples, but does not assume that the data is normally distributed\n",
    "    - tests the **null hypothesis** that **two related paired samples come from the same distribution**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon signed-rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "wilcoxon(metrics.fsel, metrics.nofsel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***p*-value** is the probability of obtaining a value of the W statistic equal to or lower than the one actually observed, under the assumption that the null hypothesis is correct.\n",
    "\n",
    "**A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis.**\n",
    "\n",
    "In other words, given a confidence level $\\alpha$ (typically 0.05), we can conclude that:\n",
    "\n",
    "- if ***p*-value $ \\leq \\alpha$**, I reject the null hypothesis (with a confidence level of $\\alpha$): result is said to be statistically significant. \n",
    "- if ***p*-value $ > \\alpha$**, I cannot reject the null hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
