{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f036d66b",
   "metadata": {},
   "source": [
    "# Table of Contents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9877ac6d",
   "metadata": {},
   "source": [
    "Major Tasks in data preprocessing:\n",
    "- Data cleaning\n",
    "    - **<font color=blue>[Handling missing values (on HYPOTHYROID dataset)](#Data-cleaning:-handling-missing-value)</font>** ✅\n",
    "    - Smooth noisy data\n",
    "    - Identify or remove outliers\n",
    "    - Resolve inconsistencies\n",
    "    - Encoding categorical features \n",
    "- Data integration\n",
    "- Data reduction\n",
    "    - Dimensionality reduction\n",
    "    - Numerosity reduction\n",
    "        - Parametric methods\n",
    "        - Non parametric methods\n",
    "            - Sampling\n",
    "                - Simple random sampling with replacement\n",
    "                - Simple random sampling without replacement\n",
    "- Data transformation and data discretization\n",
    "    - Normalization\n",
    "    - Concept Hierarchy Generation\n",
    "    - **<font color=blue>[Discretization with pandas (on IRIS dataset)](#Discretization-with-pandas)</font>** ✅\n",
    "        - <font color=blue>[Equal width binning](#Equal-width-discretization)</font> ✅\n",
    "        - <font color=blue>[Equal frequency binning](#Equal-frequency-discretization)</font> ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807177f",
   "metadata": {},
   "source": [
    "# Data cleaning: handling missing value\n",
    "Main strategies:\n",
    "- **ignoring the tuple**\n",
    "    - ⚠️ risk of shrinking the dataset too much. Problematic, for the downstream ML algorithm\n",
    "- **filling missing value manually**\n",
    "    - ⚠️ typically infeasible/tedious\n",
    "- **imputing missing value (filling automatically)**\n",
    "    - ⚠️ arbitrary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb5bbd",
   "metadata": {},
   "source": [
    "### The hypothyroid dataset\n",
    "\n",
    "Thyroid disease records supplied by the Garavan Institute and J. Ross Quinlan, New South Wales Institute, Syndney, Australia.\n",
    "\n",
    "Missing values are reported with symbol \"?\", in the original dataset\n",
    "\n",
    "|column|values|\n",
    "|---|---|\n",
    "| age|continuous (int)|\n",
    "| sex|M, F|\n",
    "| on thyroxine|f, t|\n",
    "| query on thyroxine|f, t|\n",
    "| on antithyroid medication|f, t|\n",
    "| sick|f, t|\n",
    "| pregnant|f, t|\n",
    "| thyroid surgery|f, t|\n",
    "| I131 treatment|f, t|\n",
    "| query hypothyroid|f, t|\n",
    "| query hyperthyroid|f, t|\n",
    "| lithium|f, t|\n",
    "| goitre|f, t|\n",
    "| tumor|\t\tf, t|\n",
    "| hypopituitary|\t\t\tf, t|\n",
    "| psych|\t\t\t\tf, t|\n",
    "| TSH measured|\t\t\tf, t|\n",
    "| TSH|\t\tcontinuous|\n",
    "| T3 measured|\t\t\tf, t|\n",
    "| T3|\t\t\t\tcontinuous|\n",
    "| TT4 measured|\t\t\tf, t|\n",
    "| TT4|\tcontinuous|\n",
    "| T4U measured|\t\t\tf, t|\n",
    "| T4U|\tcontinuous|\n",
    "| FTI measured|\t\t\tf, t|\n",
    "| FTI|\tcontinuous|\n",
    "| TBG measured|\t\t\tf, t|\n",
    "| TBG|\t\t\t\tcontinuous|\n",
    "| referral source|\t\tWEST, STMW, SVHC, SVI, SVHD, other|\n",
    "| Class| hypothyroid, primary hypothyroid, compensated hypothyroid, secondary hypothyroid, negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e27e08",
   "metadata": {},
   "source": [
    "Load the hypothyroid dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab51a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/hypothyroid.csv', na_values = \"?\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73613579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ee7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1060e2",
   "metadata": {},
   "source": [
    "Attribute removal:\n",
    "- \"*TBG*\" column has only missing values - we can drop it\n",
    "- \"*TBG measured*\" has only one unique value - we can drop it\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['TBG', 'TBG measured'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af367b",
   "metadata": {},
   "source": [
    "<u>Handling missing values: **ignoring the tuple**</u>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270abaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notna = df.dropna(how = 'any')\n",
    "print(df_notna.isna().sum())\n",
    "df_notna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d3b31",
   "metadata": {},
   "source": [
    "Notice that with this strategy we lost around 30% of the tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_notna) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab587e2",
   "metadata": {},
   "source": [
    "Variation of classes distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ce4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1, 2, figsize = (10, 5), sharey = True)\n",
    "\n",
    "sns.countplot(x = 'Class', \n",
    "              data = df, \n",
    "              ax = axes[0], \n",
    "              order = df_notna['Class'].value_counts().index)\n",
    "axes[0].tick_params(axis = 'x', labelrotation = 45)\n",
    "axes[0].set_title('Before removal of tuples with NaN values')\n",
    "\n",
    "sns.countplot(x = 'Class', \n",
    "              data = df_notna, \n",
    "              ax = axes[1], \n",
    "              order = df_notna['Class'].value_counts().index)\n",
    "axes[1].tick_params(axis = 'x', labelrotation = 45)\n",
    "axes[1].set_title('After removal of tuples with NaN values')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea7093",
   "metadata": {},
   "source": [
    "Variation of attribute statistics, grouped by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (10, 5), sharey = True)\n",
    "\n",
    "sns.barplot(y = 'age',\n",
    "            x = 'Class',\n",
    "            data = df, \n",
    "            ax = axes[0], \n",
    "            order = df_notna['Class'].value_counts().index)\n",
    "axes[0].tick_params(axis = 'x', labelrotation = 90)\n",
    "axes[0].grid()\n",
    "axes[0].set_title('Before removal of tuples with NaN values')\n",
    "\n",
    "sns.barplot(y = 'age', \n",
    "            x = 'Class', \n",
    "            data = df_notna, \n",
    "            ax = axes[1], \n",
    "            order = df_notna['Class'].value_counts().index)\n",
    "axes[1].tick_params(axis = 'x', labelrotation = 90)\n",
    "axes[1].set_title('After removal of tuples with NaN values')\n",
    "axes[1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6ac3d",
   "metadata": {},
   "source": [
    "<u>Handling missing values: **imputing missing value (filling automatically)**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d89039",
   "metadata": {},
   "source": [
    "Create a novel ad-hoc category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f732f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sex.fillna('NS').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b918503",
   "metadata": {},
   "source": [
    "Categorical attribute: assign the most frequent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba21446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.fillna(df.sex.mode()[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb693a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b740d4",
   "metadata": {},
   "source": [
    "Numerical attribute: assign the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815001eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.age.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.age.mean())\n",
    "df['age'].fillna(df.age.mean())[1985]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0edd2d",
   "metadata": {},
   "source": [
    "More imputing strategies available in `scikit-learn` (only for numeric attributes). We will extensively cover `scikit-learn` in the next lectures. In the following, a simple example is reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer, SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray([[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7], [3, 6, 5], [1, 3, 5], [2, 7, 5]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12f719",
   "metadata": {},
   "source": [
    "**Simple imputer**: univariate imputer for completing missing values with simple strategies.\n",
    "\n",
    "Replace missing values using a descriptive statistic (e.g. mean, median, or most frequent) along each column, or using a constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d188251",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer() # by default, it uses the \"mean\"\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3c48f",
   "metadata": {},
   "source": [
    "**KNN-imputer**: Imputation for completing missing values using k-Nearest Neighbors.\n",
    "\n",
    "Each sample’s missing values are imputed using the mean value from *n_neighbors* nearest neighbors found in the training set. Two samples are close if the features that neither is missing are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors = 2)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba20ac",
   "metadata": {},
   "source": [
    "**Iterative imputer**: Multivariate imputer that estimates each feature as a function of all the others.\n",
    "\n",
    "\n",
    "*This estimator is still experimental for now: the predictions and the API might change without any deprecation cycle.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c74cb",
   "metadata": {},
   "source": [
    "# Data Discretization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e73da2",
   "metadata": {},
   "source": [
    "Load the IRIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('dataset', 'iris.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ce3dc",
   "metadata": {},
   "source": [
    "## Discretization with pandas\n",
    "\n",
    "Sometimes we may need to transform a continuous variable to a categorical one. For example, we may want to convert ages to groups of age ranges.\n",
    "\n",
    "`Pandas` provides two functions for binning values of a continuous variable into discrete intervals. Let *x* be the input array to be binned.\n",
    "- `pd.cut(x, bins, ...)`: generic function for binning\n",
    "    - bins:\n",
    "        - *int*: number of bins (support for **equal-width** binning)\n",
    "        - *sequence of scalars*: bins edges (support for **non-uniform** width binning) \n",
    "- `pd.qcut(x, q, ...)`: quantile-based discretization function.\n",
    "    - q:\n",
    "        - *int*: number of quantiles (support for **equal-frequency** binning)\n",
    "        - *list of float*: array of quantiles (support for **custom-frequency** binning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bd30d",
   "metadata": {},
   "source": [
    "### Equal-width discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680bb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepallength_cat'], bins = pd.cut(df.sepallength, 5, retbins = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2349ca0f",
   "metadata": {},
   "source": [
    "Plot the novel categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112fb90-4a30-49ab-b192-47533d396839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c251cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'sepallength_cat', \n",
    "              hue = 'sepallength_cat', \n",
    "              data = df, \n",
    "              palette = 'pastel', \n",
    "              legend = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9c3c2",
   "metadata": {},
   "source": [
    "Plot the novel categorical variable, by class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8821f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'sepallength_cat',\n",
    "              hue = 'class',\n",
    "              data = df,\n",
    "              palette = 'pastel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810ebe0",
   "metadata": {},
   "source": [
    "How do the bins look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'sepallength', data = df)\n",
    "for edge in bins:\n",
    "    plt.axvline(edge,\n",
    "                color = 'k',\n",
    "                linestyle = '--',\n",
    "                linewidth = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360053a7",
   "metadata": {},
   "source": [
    "### Equal-frequency discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose that we want to end up with 4 categories\n",
    "nbins = 4 \n",
    "\n",
    "df['petallength_cat'], bins = pd.cut(df.petallength, nbins, retbins = True)\n",
    "df['petallength_qcat'], qbins = pd.qcut(df.petallength, nbins, retbins = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be74918",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = (10, 8), sharey = True)\n",
    "\n",
    "# axes[0][0]: top-left\n",
    "sns.countplot(x = 'petallength_cat', \n",
    "              hue = 'petallength_cat', \n",
    "              data = df, \n",
    "              palette = 'pastel', \n",
    "              ax = axes[0][0], \n",
    "              legend = False)\n",
    "axes[0][0].set_title('equal width binning')\n",
    "\n",
    "# axes[0][1]: top-right\n",
    "sns.countplot(x = 'petallength_qcat', \n",
    "              hue = 'petallength_qcat', \n",
    "              data = df, \n",
    "              palette = 'pastel', \n",
    "              ax = axes[0][1], \n",
    "              legend = False)\n",
    "axes[0][1].set_title('equal freq binning')\n",
    "\n",
    "# axes[1][0]: bottom-left\n",
    "sns.histplot(x = 'petallength',\n",
    "             data = df,\n",
    "             ax = axes[1][0])\n",
    "for edge in bins:\n",
    "    axes[1][0].axvline(edge, \n",
    "                       color = 'k',\n",
    "                       linestyle = '--',\n",
    "                       linewidth = 3)\n",
    "    \n",
    "# axes[1][1]: bottom-left\n",
    "sns.histplot(x = 'petallength',\n",
    "             data = df,\n",
    "             ax = axes[1][1])\n",
    "for edge in qbins:\n",
    "    axes[1][1].axvline(edge,\n",
    "                       color = 'k',\n",
    "                       linestyle = '--',\n",
    "                       linewidth = 3)\n",
    "\n",
    "# Improve subplot size/spacing\n",
    "fig.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0741aa2",
   "metadata": {},
   "source": [
    "**binarization** can be simply obtained using `cut()` and `qcut()` by setting nbins = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepalwidth_bin'], bins = pd.cut(df.sepalwidth, 2, retbins = True)\n",
    "df.sepalwidth_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95783bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepalwidth_qbin'], bins = pd.qcut(df.sepalwidth, 2, retbins = True)\n",
    "df.sepalwidth_qbin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d0234",
   "metadata": {},
   "source": [
    "Alternatively, we can use a simple threshold function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepalwidth_bin_custom'] = (df[\"sepalwidth\"] <= 3.0).astype(int)\n",
    "df.sepalwidth_bin_custom.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed466b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepalwidth_bin_custom'] =  (df[\"sepalwidth\"] <= 2.9).astype(int)\n",
    "df.sepalwidth_bin_custom.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ccfaf",
   "metadata": {},
   "source": [
    "`qcut()` does its best to get equifrequent bins, but of course it depends on the data and the numerical precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964dda8",
   "metadata": {},
   "source": [
    "### From categorical to numerical\n",
    "Note that ordinal / interval scaled variable should be treated as such for downstream elaboration (e.g., similarity/distance evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeccd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e27f81",
   "metadata": {},
   "source": [
    "Consider, for example, the breast_cancer dataset:\n",
    "\n",
    "| column | values |\n",
    "| --- | --- |\n",
    "| Class | no-recurrence-events, recurrence-events |\n",
    "| age | 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99|\n",
    "| menopause | lt40, ge40, premeno|\n",
    "| tumor-size | 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59|\n",
    "| inv-nodes | 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39|\n",
    "| node-caps | yes, no|\n",
    "| deg-malig | 1, 2, 3|\n",
    "| breast | left, right|\n",
    "| breast-quad | left-up, left-low, right-up, right-low, central|\n",
    "| irradiat | yes, no|\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d83fb2",
   "metadata": {},
   "source": [
    "Suppose that a iris_cat dataset is represented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['sepallength_cat', 'petallength_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_cat_df = df[categorical_variables].copy() # a new object will be created with a copy of the calling object’s data and indices.\n",
    "iris_cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c88529",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_cat_df['sepallength_mean'] = iris_cat_df.sepallength_cat.apply(lambda x: x.mid)\n",
    "iris_cat_df['petallength_mean'] = iris_cat_df.petallength_cat.apply(lambda x: x.mid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390a43a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_num = iris_cat_df.iloc[:, -2:]\n",
    "iris_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e09e8d",
   "metadata": {},
   "source": [
    "The *mid* attribute is convenient when we have pandas CategoricalDtype.\n",
    "\n",
    "In general, we can define custom mappings: e.g., how could we handle the age variable of breast_cancer, in which intervals are represented as strings?\n",
    "\n",
    "```python\n",
    "dict_categories: {\"10-19\":15, \"20-29\":25, \"30-39\":35, \"40-49\":45, \"50-59\":55, \"60-69\":65, \"70-79\":75, \"80-89\":85, \"90-99\":95}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
